{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotional AI Chatbot Using Dorner's Psi Theory\n",
    "\n",
    "This notebook explores the development of an emotional AI chatbot by integrating Dorner's Psi Theory for understanding and simulating emotional responses. It dynamically calculates and displays sadness and anger levels during a conversation, adapting its dialogue accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from flask import Flask, render_template, request, jsonify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define Emotional Model\n",
    "\n",
    "#### Dorner's Psi Theory Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Emotion Levels: {'anger': 1.54, 'sadness': 0.08}\n"
     ]
    }
   ],
   "source": [
    "# Valence: Spectrum of attraction vs. aversion (1-7).\n",
    "# Arousal: Readiness for action (1-7).\n",
    "# Selection Threshold: Ease of intention shifting (1-7).\n",
    "# Resolution: Perceptual accuracy (1-7).\n",
    "# Goal Directedness: Stability of motives (1-7).\n",
    "\n",
    "def calculate_emotional_state(valence, arousal, selection_threshold, resolution, goal_directedness):\n",
    "    \"\"\"\n",
    "    Calculate the anger and sadness levels based on Dorner's Psi Theory parameters.\n",
    "    \n",
    "    Parameters:\n",
    "        valence (float): Spectrum of attraction vs. aversion (1-7).\n",
    "        arousal (float): Readiness for action (1-7).\n",
    "        selection_threshold (float): Ease of intention shifting (1-7).\n",
    "        resolution (float): Perceptual accuracy (1-7).\n",
    "        goal_directedness (float): Stability of motives (1-7).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Calculated anger and sadness levels.\n",
    "    \"\"\"\n",
    "    anger = max(0, (arousal * (7 - valence) * goal_directedness) / 35)\n",
    "    sadness = max(0, ((7 - arousal) * (7 - goal_directedness)) / 49)\n",
    "    return {\n",
    "        \"anger\": round(min(anger, 5), 2),\n",
    "        \"sadness\": round(min(sadness, 5), 2)\n",
    "    }\n",
    "\n",
    "# Test the function with example values\n",
    "example_emotions = calculate_emotional_state(4, 6, 5, 4, 3)\n",
    "print(\"Example Emotion Levels:\", example_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Set Up the Chatbot\n",
    "### Define Chatbot Logic Using OpenRouter and Google Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.runnables import Runnable\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize LangChain's memory for conversation context\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Configuration for OpenRouter API\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "OPENROUTER_BASE_URL = os.getenv(\"OPENROUTER_BASE_URL\")\n",
    "\n",
    "def initialize_chatbot():\n",
    "    \"\"\"Initialize the chatbot using OpenRouter with Google Gemini model.\"\"\"\n",
    "    client = OpenAI(\n",
    "        base_url=OPENROUTER_BASE_URL,\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "    )\n",
    "\n",
    "    class GeminiWrapper(Runnable):\n",
    "        def invoke(self, prompt, config=None, **kwargs):\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"google/gemini-exp-1121:free\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "\n",
    "    chain = ConversationChain(llm=GeminiWrapper(), memory=memory, verbose=True)\n",
    "    return chain\n",
    "\n",
    "chatbot = initialize_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
