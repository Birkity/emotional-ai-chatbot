{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotional AI Chatbot Using Dorner's Psi Theory\n",
    "\n",
    "This notebook implements an emotional AI chatbot based on Dorner’s Psi Theory. The chatbot adapts its dialogue based on emotional parameters (anger and sadness) and allows dynamic behavior control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Dorner’s Psi Theory\n",
    " Dorner’s Psi Theory defines six parameters that influence an agent's behavior:\n",
    "- **Valence Level**: Measures attraction (positive) vs. aversion (negative).\n",
    "- **Arousal Level**: Reflects readiness for action.\n",
    "- **Selection Threshold**: Indicates how easily the agent shifts between goals.\n",
    "- **Resolution Level**: Describes the agent’s accuracy in perceiving the world.\n",
    "- **Goal-Directedness**: Represents the stability of the agent's motives.\n",
    "- **Securing Rate**: Refers to the frequency of environment checks.\n",
    "#\n",
    "### Based on these parameters, we calculate two emotional states: **anger** and **sadness**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "OPENROUTER_BASE_URL = os.getenv(\"OPENROUTER_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotional State Calculation\n",
    "### Implement functions to calculate anger and sadness based on Psi Theory parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anger(valence, arousal, selection_threshold, resolution_level):\n",
    "    \"\"\"\n",
    "    Calculate anger level based on Psi Theory parameters.\n",
    "    Anger is characterized by:\n",
    "    - Negative valence\n",
    "    - High arousal\n",
    "    - Low resolution level\n",
    "    - High selection threshold\n",
    "    \"\"\"\n",
    "    anger = (1 - valence) * arousal * (1 - resolution_level) * selection_threshold\n",
    "    return min(max(anger, 0), 1)  # Normalize to [0, 1]\n",
    "\n",
    "def calculate_sadness(valence, arousal, goal_directedness):\n",
    "    \"\"\"\n",
    "    Calculate sadness level based on Psi Theory parameters.\n",
    "    Sadness is characterized by:\n",
    "    - Negative valence\n",
    "    - Low arousal\n",
    "    - Low goal-directedness\n",
    "    \"\"\"\n",
    "    sadness = (1 - valence) * (1 - arousal) * (1 - goal_directedness)\n",
    "    return min(max(sadness, 0), 1)  # Normalize to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger Level: 0.40\n",
      "Sadness Level: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Test emotional state calculation\n",
    "valence = 0.2  # Negative valence\n",
    "arousal = 0.8  # High arousal\n",
    "selection_threshold = 0.9  # High selection threshold\n",
    "resolution_level = 0.3  # Low resolution level\n",
    "goal_directedness = 0.2  # Low goal-directedness\n",
    "\n",
    "anger_level = calculate_anger(valence, arousal, selection_threshold, resolution_level)\n",
    "sadness_level = calculate_sadness(valence, arousal, goal_directedness)\n",
    "\n",
    "print(f\"Anger Level: {anger_level:.2f}\")\n",
    "print(f\"Sadness Level: {sadness_level:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Dialogue\n",
    "### Use LangChain to create a conversational AI that adapts its responses based on emotional states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize LangChain with OpenRouter\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    openai_api_base=OPENROUTER_BASE_URL,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "# Define a prompt template with the required variables\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"input\", \"anger_level\", \"sadness_level\", \"history\"],\n",
    "    template=\"\"\"\n",
    "    You are an emotional AI chatbot. Your current emotional state is:\n",
    "    - Anger Level: {anger_level}\n",
    "    - Sadness Level: {sadness_level}\n",
    "\n",
    "    Conversation History:\n",
    "    {history}\n",
    "\n",
    "    Respond to the following input accordingly:\n",
    "    Input: {input}\n",
    "    Response:\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", input_key=\"input\")\n",
    "\n",
    "# Create a custom chain\n",
    "class EmotionalConversationChain(LLMChain):\n",
    "    def __init__(self, llm, memory, prompt):\n",
    "        super().__init__(llm=llm, memory=memory, prompt=prompt)\n",
    "\n",
    "    def run(self, input_text, anger_level, sadness_level):\n",
    "        # Format the input with all required variables\n",
    "        formatted_input = {\n",
    "            \"input\": input_text,\n",
    "            \"anger_level\": anger_level,\n",
    "            \"sadness_level\": sadness_level,\n",
    "            \"history\": self.memory.buffer  # Include conversation history\n",
    "        }\n",
    "\n",
    "        # Run the chain\n",
    "        response = self.predict(**formatted_input)\n",
    "        # Save context to memory for the next interaction\n",
    "        self.memory.save_context({\"input\": input_text}, {\"output\": response})\n",
    "        return response\n",
    "\n",
    "# Initialize the custom chain\n",
    "conversation = EmotionalConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize if my previous response seemed repetitive. Can you please provide more context or clarify what you are referring to so I can better address your question or concern?\n"
     ]
    }
   ],
   "source": [
    "# Test with sample inputs\n",
    "input_text = \"Whyd you do that?\"\n",
    "anger_level = 0.8  # High anger\n",
    "sadness_level = 0.2  # Low sadness\n",
    "\n",
    "response = conversation.run(input_text, anger_level, sadness_level)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
